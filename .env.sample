# LLM Gateway Configuration
# Point this to your internal OpenAI-compatible endpoint
AI_API_BASE_URL=http://internal-ai-gateway.corp/v1

# Your Internal API Key
AI_API_KEY=sk-internal-key-xxxxx

# Model Deployment Name
AI_MODEL_NAME=gpt-4-turbo-internal

# Proxy Server Settings
PORT=8000
DEBUG=True
